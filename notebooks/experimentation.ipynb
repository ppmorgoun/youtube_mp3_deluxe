{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.options.display.max_rows = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the perfect dataset\n",
    "\n",
    "The objective goal of this model is to classify my favorites and liked playlists into song and not songs. Both these playlists are already mainly songs (I estimate 99% music for my favorites and 95% music for the liked videos)\n",
    "\n",
    "Should my training dataset also be ~95% music and only 5% other videos? I think so as this is similar to the distribution of the target I truly care about.\n",
    "\n",
    "Metric of choice: ROC-AUC score\n",
    "\n",
    "### Type of music videos in my playlists:\n",
    "* Individual songs (with and without music videos)\n",
    "* Mixes\n",
    "\n",
    "### Types of 'other' videos found in my playlists:\n",
    "* Gaming videos\n",
    "* Podcasts\n",
    "* Video essays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "songsPath = '../data/music_data/'\n",
    "nonSongsPath = '../data/non_music_data'\n",
    "\n",
    "# Populate a dataframe each for all songs and non-songs\n",
    "\n",
    "# Songs first\n",
    "songsCSVList = Path(songsPath).rglob('*.csv')\n",
    "music_df = pd.concat([pd.read_csv(str(i), index_col = 0) for i in songsCSVList])\n",
    "\n",
    "# Now non-songs\n",
    "nonSongsCSVList = Path(nonSongsPath).rglob('*.csv')\n",
    "nonMusic_df = pd.concat([pd.read_csv(str(i), index_col = 0) for i in nonSongsCSVList])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired number of non_songs = 46 relative to 868 songs\n",
      "The shape of the full dataframe is (914, 5) where 95.0% of the observations are songs and 5.0% are not\n"
     ]
    }
   ],
   "source": [
    "# Adding a target variable column where music = 1, not music = 0\n",
    "\n",
    "music_df['is_song'] = 1\n",
    "nonMusic_df['is_song'] = 0\n",
    "\n",
    "# Joining them into one dataset\n",
    "# Got to balance the dataset first to ensure no more than 5% of the video are non-songs\n",
    "\n",
    "num_songs = len(music_df)\n",
    "num_nonSongs = len(nonMusic_df)\n",
    "percent_songs = 0.95 # desired class balance in terms of percentage of songs\n",
    "desired_num = round((num_songs / percent_songs) - num_songs)\n",
    "# Shuffle non_music df\n",
    "balancedNonMusic_df = nonMusic_df.sample(frac=1).reset_index(drop=True)\n",
    "balancedNonMusic_df = balancedNonMusic_df[:desired_num]\n",
    "\n",
    "print(f\"Desired number of non_songs = {desired_num} relative to {num_songs} songs\")\n",
    "\n",
    "\n",
    "df = pd.concat([music_df, balancedNonMusic_df], axis=0).reset_index().drop(labels='index', axis=1)\n",
    "is_song_pct, is_not_song_pct = df['is_song'].value_counts(normalize=True)\n",
    "print(f'The shape of the full dataframe is {df.shape} where {round(is_song_pct, 2)*100}% of the observations are songs and {round(is_not_song_pct, 2)*100}% are not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the song Titles and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    # Remove non-alphanumeric characters\n",
    "    data = data.apply(lambda x: re.sub('[^a-zA-Z\\-]', ' ', x))\n",
    "\n",
    "    # Remove extra whitespace and lowercase text \n",
    "    data = data.apply(lambda x: ' '.join(x.lower().split()))\n",
    "\n",
    "    # Remove short words\n",
    "    data = data.apply(lambda x: ' '.join(x for x in x.split() if len(x) > 2 or x == '-'))\n",
    "    \n",
    "    # Stop words will be removed in vectorizer\n",
    "    return data\n",
    "\n",
    "# Tokenizer function\n",
    "def tokenizer(title):\n",
    "    # Create a list of tokens\n",
    "    tokens = []\n",
    "    # Split title into words\n",
    "    words = title.split()\n",
    "    # Iterate through the words in the title\n",
    "    for word in words:\n",
    "        tokens.append(word)\n",
    "          \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Index</th>\n",
       "      <th>Duration</th>\n",
       "      <th>is_song</th>\n",
       "      <th>cleanTitles</th>\n",
       "      <th>Title Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illenium - Crawl Outta Love (feat. Annika Wells)</td>\n",
       "      <td>https://www.youtube.com/watch?v=5CMuZrTy6jw</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>illenium - crawl outta love feat annika wells</td>\n",
       "      <td>[illenium, -, crawl, outta, love, feat, annika...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bronze Whale - Patterns</td>\n",
       "      <td>https://www.youtube.com/watch?v=ifHi5TV1Uzk</td>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>bronze whale - patterns</td>\n",
       "      <td>[bronze, whale, -, patterns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LissA x MEMBA - Sun's Up</td>\n",
       "      <td>https://www.youtube.com/watch?v=opwluvYuiyI</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>lissa memba - sun</td>\n",
       "      <td>[lissa, memba, -, sun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two Feet - Love Is A Bitch</td>\n",
       "      <td>https://www.youtube.com/watch?v=_DjE4gbIVZk</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>two feet - love bitch</td>\n",
       "      <td>[two, feet, -, love, bitch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flux Pavilion - Somebody Else (feat. GLNNA)</td>\n",
       "      <td>https://www.youtube.com/watch?v=eH-55GN9Dos</td>\n",
       "      <td>5</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>flux pavilion - somebody else feat glnna</td>\n",
       "      <td>[flux, pavilion, -, somebody, else, feat, glnna]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  \\\n",
       "0  Illenium - Crawl Outta Love (feat. Annika Wells)   \n",
       "1                           Bronze Whale - Patterns   \n",
       "2                          LissA x MEMBA - Sun's Up   \n",
       "3                        Two Feet - Love Is A Bitch   \n",
       "4       Flux Pavilion - Somebody Else (feat. GLNNA)   \n",
       "\n",
       "                                           URL  Index  Duration  is_song  \\\n",
       "0  https://www.youtube.com/watch?v=5CMuZrTy6jw      1       242        1   \n",
       "1  https://www.youtube.com/watch?v=ifHi5TV1Uzk      2       193        1   \n",
       "2  https://www.youtube.com/watch?v=opwluvYuiyI      3       200        1   \n",
       "3  https://www.youtube.com/watch?v=_DjE4gbIVZk      4       178        1   \n",
       "4  https://www.youtube.com/watch?v=eH-55GN9Dos      5       240        1   \n",
       "\n",
       "                                     cleanTitles  \\\n",
       "0  illenium - crawl outta love feat annika wells   \n",
       "1                        bronze whale - patterns   \n",
       "2                              lissa memba - sun   \n",
       "3                          two feet - love bitch   \n",
       "4       flux pavilion - somebody else feat glnna   \n",
       "\n",
       "                                        Title Tokens  \n",
       "0  [illenium, -, crawl, outta, love, feat, annika...  \n",
       "1                       [bronze, whale, -, patterns]  \n",
       "2                             [lissa, memba, -, sun]  \n",
       "3                        [two, feet, -, love, bitch]  \n",
       "4   [flux, pavilion, -, somebody, else, feat, glnna]  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleanTitles'] = clean_data(df['Title'])\n",
    "df['Title Tokens'] = df['cleanTitles'].apply(tokenizer)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(tokens):\n",
    "    \"\"\"\n",
    "    Calculates some basic statistics about tokens in our corpus (i.e. corpus means collections text data)\n",
    "    \"\"\"\n",
    "    # stores the count of each token\n",
    "    word_counts = Counter()\n",
    "    \n",
    "    # stores the number of docs that each token appears in \n",
    "    appears_in = Counter()\n",
    "\n",
    "    total_docs = len(tokens)\n",
    "\n",
    "    for token in tokens:\n",
    "        # stores count of every appearance of a token \n",
    "        word_counts.update(token)\n",
    "        # use set() in order to not count duplicates, thereby count the num of docs that each token appears in\n",
    "        appears_in.update(set(token))\n",
    "\n",
    "    # build word count dataframe\n",
    "    temp = zip(word_counts.keys(), word_counts.values())\n",
    "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "    # rank the the word counts\n",
    "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "    total = wc['count'].sum()\n",
    "\n",
    "    # calculate the percent total of each token\n",
    "    wc['pct_total'] = wc['count'].apply(lambda token_count: token_count / total)\n",
    "\n",
    "    # calculate the cumulative percent total of word counts \n",
    "    wc = wc.sort_values(by='rank')\n",
    "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "    # create dataframe for document stats\n",
    "    t2 = zip(appears_in.keys(), appears_in.values())\n",
    "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "    \n",
    "    # merge word count stats with doc stats\n",
    "    wc = ac.merge(wc, on='word')\n",
    "\n",
    "    wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "\n",
    "    return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>appears_in</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_total</th>\n",
       "      <th>cul_pct_total</th>\n",
       "      <th>appears_in_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>738</td>\n",
       "      <td>758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131346</td>\n",
       "      <td>0.131346</td>\n",
       "      <td>0.807440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>official</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>0.266958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>video</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>0.249453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>the</td>\n",
       "      <td>131</td>\n",
       "      <td>149</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.025819</td>\n",
       "      <td>0.238953</td>\n",
       "      <td>0.143326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feat</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.257841</td>\n",
       "      <td>0.119256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  appears_in  count  rank  pct_total  cul_pct_total  \\\n",
       "7           -         738    758   1.0   0.131346       0.131346   \n",
       "535  official         244    244   2.0   0.042280       0.173627   \n",
       "538     video         228    228   3.0   0.039508       0.213135   \n",
       "102       the         131    149   4.0   0.025819       0.238953   \n",
       "1        feat         109    109   5.0   0.018888       0.257841   \n",
       "\n",
       "     appears_in_pct  \n",
       "7          0.807440  \n",
       "535        0.266958  \n",
       "538        0.249453  \n",
       "102        0.143326  \n",
       "1          0.119256  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc  = count(df['Title Tokens'])\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting our data in validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((620, 2), (620,), (156, 2), (156,), (138, 2), (138,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data\n",
    "features = ['cleanTitles', 'Duration']\n",
    "\n",
    "target = 'is_song'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "indexes = {'train': X_train.index.tolist(), 'val': X_val.index.tolist(), 'test': X_test.index.tolist()}\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features from song titles using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm dataframe shape: (620, 104)\n",
      "X_val_dtm dataframe shape: (156, 104)\n",
      "X_test_dtm dataframe shape: (138, 104)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english', ngram_range=(1,2),\n",
    "    min_df=5,\n",
    "    max_features=1000,\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# First create our TF-IDF from our training dataset\n",
    "X_train_dtm = tfidf.fit_transform(X_train['cleanTitles'])\n",
    "X_train_dtm = pd.DataFrame(data=X_train_dtm.toarray(), columns=tfidf.get_feature_names(), index=X_train.index)\n",
    "X_train_dtm['Duration'] = X_train['Duration']\n",
    "print(f\"X_train_dtm dataframe shape: {X_train_dtm.shape}\")\n",
    "\n",
    "# Transoforming X_val\n",
    "X_val_dtm = tfidf.transform(X_val['cleanTitles'])\n",
    "X_val_dtm = pd.DataFrame(data=X_val_dtm.toarray(), columns=tfidf.get_feature_names(), index=X_val.index)\n",
    "X_val_dtm['Duration'] = X_val['Duration']\n",
    "print(f\"X_val_dtm dataframe shape: {X_val_dtm.shape}\")\n",
    "\n",
    "# And X_test\n",
    "X_test_dtm = tfidf.transform(X_test['cleanTitles'])\n",
    "X_test_dtm = pd.DataFrame(data=X_test_dtm.toarray(), columns=tfidf.get_feature_names(), index=X_test.index)\n",
    "X_test_dtm['Duration'] = X_test['Duration']\n",
    "print(f\"X_test_dtm dataframe shape: {X_test_dtm.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP:\n",
    "## Random forest model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline RF model\n",
    "# Imports \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "from sklearn.metrics import accuracy_score as acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "\n",
    "clf.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training ROC AUC score of my baseline model is: 0.9991496598639455\n",
      "The validation ROC AUC score of my baseline model is: 0.7756471716203259\n",
      "\n",
      "The training accuracy score of my baseline model is: 0.9983870967741936\n",
      "The validation accuracy score of my baseline model is: 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# Results: \n",
    "\n",
    "y_pred = clf.predict(X_val_dtm)\n",
    "y_pred_train = clf.predict(X_train_dtm)\n",
    "\n",
    "roc_auc_val = roc_auc(y_val, y_pred)\n",
    "roc_auc_train = roc_auc(y_train, y_pred_train)\n",
    "\n",
    "print(f'The training ROC AUC score of my baseline model is: {roc_auc_train}')\n",
    "print(f'The validation ROC AUC score of my baseline model is: {roc_auc_val}')\n",
    "\n",
    "# Calculating accuracy\n",
    "acc_val = acc(y_val, y_pred)\n",
    "acc_train = acc(y_train, y_pred_train)\n",
    "\n",
    "print(f'\\nThe training accuracy score of my baseline model is: {acc_train}')\n",
    "print(f'The validation accuracy score of my baseline model is: {acc_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations that were misclassified: 6\n",
      "96.0% accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanTitles</th>\n",
       "      <th>Duration</th>\n",
       "      <th>is_song_pred</th>\n",
       "      <th>is_song</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>morning rain</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Morning Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>crash test for dogs</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Crash Test For Dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>the nomad</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The Nomad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>the boy who cried literally</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The Boy Who Cried Literally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>photoshop has gone too far</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Photoshop Has Gone Too Far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>india lament</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>India's Lament</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     cleanTitles  Duration  is_song_pred  is_song  \\\n",
       "450                 morning rain       131             0        1   \n",
       "906          crash test for dogs       171             1        0   \n",
       "393                    the nomad       180             0        1   \n",
       "876  the boy who cried literally       154             1        0   \n",
       "891   photoshop has gone too far       101             1        0   \n",
       "383                 india lament       162             0        1   \n",
       "\n",
       "                           Title  \n",
       "450                 Morning Rain  \n",
       "906          Crash Test For Dogs  \n",
       "393                    The Nomad  \n",
       "876  The Boy Who Cried Literally  \n",
       "891   Photoshop Has Gone Too Far  \n",
       "383               India's Lament  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at which validation observations the model got incorrect\n",
    "X_val_check = X_val.set_index([indexes['val']])\n",
    "X_val_check['is_song_pred'] = y_pred\n",
    "X_val_check['is_song'] = y_val\n",
    "X_val_check = X_val_check[X_val_check['is_song_pred'] != X_val_check['is_song']]\n",
    "print(f'The number of observations that were misclassified: {X_val_check.shape[0]}\\n'\n",
    "    f'{(1-round(X_val_check.shape[0] /  X_val.shape[0], 2))*100}% accuracy')\n",
    "\n",
    "titles = df[['Title']]\n",
    "to_inspect = X_val_check.merge(titles, how='inner', left_index=True, right_index=True)\n",
    "to_inspect.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 103 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-f654579160ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportances_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportances_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportances_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          print(f\"{X.columns[i]} \"\n\u001b[0m\u001b[1;32m      9\u001b[0m                \u001b[0;34mf\"{r.importances_mean[i]:.3f}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                f\" +/- {r.importances_std[i]:.3f}\")\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4296\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4297\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 103 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "### Me trying to check permutation importances using sklearn's library\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "r = permutation_importance(clf, X_val_dtm, y_val, n_repeats=40)\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "         print(f\"{X.columns[i]} \"\n",
    "               f\"{r.importances_mean[i]:.3f}\"\n",
    "               f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = { \n",
    "    'n_estimators': randint(50, 500), \n",
    "    'max_depth': [5, 10, 15, 20, None], \n",
    "    'max_features': uniform(0, 1), \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    clf, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=50, \n",
    "    cv=5, \n",
    "    scoring='roc_auc', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train_dtm, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'max_depth': 5, 'max_features': 0.8997099441178155, 'n_estimators': 488}\n",
      "Cross-validation ROC-AUC score 0.9333943833943834\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation ROC-AUC score', search.best_score_)\n",
    "tuned_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training ROC AUC score of my baseline model is: 0.640625\n",
      "The validation ROC AUC score of my baseline model is: 0.6428571428571428\n",
      "\n",
      "The training accuracy score of my baseline model is: 0.9629032258064516\n",
      "The validation accuracy score of my baseline model is: 0.967948717948718\n"
     ]
    }
   ],
   "source": [
    "# Double checking my ROC-AUC scores\n",
    "# Results: \n",
    "\n",
    "y_pred = tuned_model.predict(X_val_dtm)\n",
    "y_pred_train = tuned_model.predict(X_train_dtm)\n",
    "\n",
    "roc_auc_val = roc_auc(y_val, y_pred)\n",
    "roc_auc_train = roc_auc(y_train, y_pred_train)\n",
    "\n",
    "print(f'The training ROC AUC score of my baseline model is: {roc_auc_train}')\n",
    "print(f'The validation ROC AUC score of my baseline model is: {roc_auc_val}')\n",
    "\n",
    "# Calculating accuracy\n",
    "acc_val = acc(y_val, y_pred)\n",
    "acc_train = acc(y_train, y_pred_train)\n",
    "\n",
    "print(f'\\nThe training accuracy score of my baseline model is: {acc_train}')\n",
    "print(f'The validation accuracy score of my baseline model is: {acc_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best I could seem to get the randomized search CV tuned hyperparamter model is an ROC-AUCscore of 64.3, worse by 13 points than the naive model\n",
    "\n",
    "Why is this? \n",
    " - Not exhaustive enough a search\n",
    " - Doing something wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('3.8.3': pyenv)",
   "language": "python",
   "name": "python38364bit383pyenv9fc8690d20b94dae95512165dd4116a0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
